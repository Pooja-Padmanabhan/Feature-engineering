{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee2514a2",
   "metadata": {},
   "source": [
    "### 1. Import and understand the data.\n",
    "### A. Import ‘signal-data.csv’ as DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e31a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Downloads/signal-data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf160c3",
   "metadata": {},
   "source": [
    "The dataframe 'signal-data.csv' is impoerted and stored in the variable df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8f8d8d",
   "metadata": {},
   "source": [
    "### B. Print 5 point summary and share at least 2 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e734f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd69150",
   "metadata": {},
   "source": [
    "Atleast 2 Observations:\n",
    "    The mean value of -0.867262 indicates that, on average, the data points are closer to the \"pass\" category represented by -1 rather than the \"fail\" category represented by 1. This suggests that the majority of the observations tend to fall within the \"pass\" range rather than the \"fail\" range.\n",
    "    With a standard deviation value of 0.498010, the data points show relatively low dispersion around the mean. This indicates that the values are clustered closely together, suggesting a relatively consistent pattern in the dataset. The combination of a mean value close to -1 and a low standard deviation suggests that the majority of observations are likely to be in the \"pass\" category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ec96f",
   "metadata": {},
   "source": [
    "### 2. Data cleansing:\n",
    "### A. Write a for loop which will remove all the features with 20%+ Null values and impute rest with mean of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded91cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Time'] = pd.to_numeric(df['Time'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c16948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c3213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_spaces = (df == '').sum()\n",
    "\n",
    "# Check if any blank spaces exist\n",
    "if blank_spaces.sum() > 0:\n",
    "    print(\"Blank spaces exist in the DataFrame.\")\n",
    "    # Print the count of blank spaces for each column\n",
    "    print(blank_spaces)\n",
    "else:\n",
    "    print(\"No blank spaces found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd3721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values = df.isnull().sum()\n",
    "\n",
    "# Check if any null values exist\n",
    "if null_values.sum() > 0:\n",
    "    print(\"Null values exist in the DataFrame.\")\n",
    "    # Print the count of null values for each column\n",
    "    print(null_values)\n",
    "else:\n",
    "    print(\"No null values found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f3afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of null values for each feature\n",
    "null_percentages = df.isnull().mean() * 100\n",
    "\n",
    "# Create an empty list to store the features to be removed\n",
    "features_to_remove = []\n",
    "\n",
    "# Iterate over each feature and check if it has 20% or more null values\n",
    "for feature in df.columns:\n",
    "    if null_percentages[feature] >= 20:\n",
    "        features_to_remove.append(feature)\n",
    "    else:\n",
    "        # Impute the missing values with the mean of the feature\n",
    "        df[feature].fillna(df[feature].mean(), inplace=True)\n",
    "\n",
    "# Remove the features with 20% or more null values from the DataFrame\n",
    "df.drop(features_to_remove, axis=1, inplace=True)\n",
    "\n",
    "# Check if the query is met\n",
    "if len(features_to_remove) > 0:\n",
    "    print(\"Features with 20% or more null values have been removed.\")\n",
    "else:\n",
    "    print(\"No features with 20% or more null values found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb253986",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa1c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values = df.isnull().sum()\n",
    "\n",
    "# Check if any null values exist\n",
    "if null_values.sum() > 0:\n",
    "    print(\"Null values exist in the DataFrame.\")\n",
    "    # Print the count of null values for each column\n",
    "    print(null_values)\n",
    "else:\n",
    "    print(\"No null values found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245e7467",
   "metadata": {},
   "source": [
    "### B. Identify and drop the features which are having same value for all the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c8af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of unique values for each feature\n",
    "unique_counts = df.nunique()\n",
    "\n",
    "# Identify features with only one unique value\n",
    "features_to_drop = unique_counts[unique_counts == 1].index\n",
    "\n",
    "# Drop the features with only one unique value from the DataFrame\n",
    "df.drop(features_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Print the list of dropped features\n",
    "print(\"Dropped features:\", features_to_drop.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c813a195",
   "metadata": {},
   "source": [
    "### C. Drop other features if required using relevant functional knowledge. Clearly justify the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e52bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c02f804",
   "metadata": {},
   "source": [
    "No other features requires to be dropped as the features contain data which carries value to the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe7f48c",
   "metadata": {},
   "source": [
    "### D. Check for multi-collinearity in the data and take necessary action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24885a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "print(corr_matrix)\n",
    "\n",
    "# Calculate the VIF for each feature\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Feature\"] = df.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "\n",
    "# Print the VIF results\n",
    "print(\"Variance Inflation Factors (VIF):\")\n",
    "print(vif)\n",
    "\n",
    "# Drop features with high VIF\n",
    "threshold = 10  # Adjust this threshold as needed\n",
    "high_vif_features = vif[vif[\"VIF\"] > threshold][\"Feature\"]\n",
    "df = df.drop(high_vif_features, axis=1)\n",
    "\n",
    "# Print the modified dataset\n",
    "print(\"Modified Dataset:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c5fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de174c",
   "metadata": {},
   "source": [
    "### E. Make all relevant modifications on the data using both functional/logical reasoning/assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a679aed0",
   "metadata": {},
   "source": [
    "First, we compute the correlation matrix using the corr() function on the dataset. The correlation matrix shows the pairwise correlations between all the features.\n",
    "\n",
    "Next, we calculate the VIF for each feature using the variance_inflation_factor() function from the statsmodels library. The VIF measures the extent of multicollinearity in a feature by estimating how much the variance of the estimated regression coefficients is increased due to multicollinearity.\n",
    "\n",
    "We create a DataFrame vif to store the feature names and their corresponding VIF values.\n",
    "\n",
    "Then, we print the correlation matrix and the VIF results.\n",
    "\n",
    "Based on the VIF values, you can set a threshold (e.g., 10) to identify features with high multicollinearity. The code identifies the features with VIF values above the threshold and stores them in the high_vif_features variable.\n",
    "\n",
    "Finally, we drop the features with high VIF from the dataset using the drop() function and store the modified dataset in the df variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9e37b5",
   "metadata": {},
   "source": [
    "### 3. Data analysis & visualisation:\n",
    "### A. Perform a detailed univariate Analysis with appropriate detailed comments after each analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e3918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Iterate over each feature in the DataFrame\n",
    "for feature in df.columns:\n",
    "    print(\"Feature:\", feature)\n",
    "    print(\"------------------------------\")\n",
    "\n",
    "    # Histogram\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(df[feature], bins=20)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Histogram of \" + feature)\n",
    "    plt.show()\n",
    "\n",
    "    # Box plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot(df[feature])\n",
    "    plt.xlabel(feature)\n",
    "    plt.title(\"Box Plot of \" + feature)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # Descriptive statistics\n",
    "    print(\"Comments and observations:- Descriptive Statistics:\")\n",
    "    print(df[feature].describe())\n",
    "    print()\n",
    "    print(\"------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4c8a9",
   "metadata": {},
   "source": [
    "### B. Perform bivariate and multivariate analysis with appropriate detailed comments after each analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70fef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Bivariate analysis (relationship between two variables)\n",
    "print(\"Bivariate Analysis\")\n",
    "print(\"------------------\")\n",
    "\n",
    "# Iterate over pairs of features for bivariate analysis\n",
    "for feature1 in df.columns:\n",
    "    for feature2 in df.columns:\n",
    "        if feature1 != feature2:\n",
    "            print(\"Analysis between\", feature1, \"and\", feature2)\n",
    "            print(\"---------------------------------\")\n",
    "\n",
    "            # Scatter plot\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.scatterplot(data=df, x=feature1, y=feature2)\n",
    "            plt.xlabel(feature1)\n",
    "            plt.ylabel(feature2)\n",
    "            plt.title(\"Scatter Plot: \" + feature1 + \" vs \" + feature2)\n",
    "            plt.show()\n",
    "\n",
    "            # Correlation coefficient\n",
    "            correlation_coefficient = df[feature1].corr(df[feature2])\n",
    "            print(\"Correlation Coefficient:\", correlation_coefficient)\n",
    "            print()\n",
    "            print(\"---------------------------------\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5401d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Multivariate analysis (relationship among multiple variables)\n",
    "print(\"Multivariate Analysis\")\n",
    "print(\"----------------------\")\n",
    "\n",
    "# Correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(30, 30))\n",
    "sns.heatmap(data=correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Matrix Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde442a",
   "metadata": {},
   "source": [
    "### 4. Data pre-processing\n",
    "### A. Segregate predictors vs target attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregate predictors and target attributes\n",
    "predictors = df.drop('Pass/Fail', axis=1)  # Drop the target attribute column\n",
    "target = df['Pass/Fail']  # Select the target attribute column\n",
    "\n",
    "# Print the predictors and target attributes\n",
    "print(\"Predictors:\")\n",
    "print(predictors.head())\n",
    "print()\n",
    "\n",
    "print(\"Target Attribute:\")\n",
    "print(target.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40c0f49",
   "metadata": {},
   "source": [
    "### B. Check for target balancing and fix it if found imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f009d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a DataFrame called 'data' containing your data\n",
    "# and the target attribute is named 'target_attribute'\n",
    "\n",
    "# Check target balance\n",
    "target_counts = df['Pass/Fail'].value_counts()\n",
    "target_balance = target_counts / len(df) * 100\n",
    "\n",
    "print(\"Target Balance:\")\n",
    "print(target_balance)\n",
    "print()\n",
    "\n",
    "# Plot target distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "target_counts.plot(kind='bar')\n",
    "plt.xlabel(\"Target Attribute\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Target Distribution\")\n",
    "plt.show()\n",
    "\n",
    "if target_balance.min() < 5 or target_balance.max() > 95:\n",
    "    print(\"Target not balanced\")\n",
    "    # Perform techniques to address target imbalance\n",
    "    # Example techniques include oversampling, undersampling, or synthetic data generation\n",
    "\n",
    "    # Apply the chosen technique and update the DataFrame if needed\n",
    "    # balanced_data = ...  # Perform oversampling, undersampling, or synthetic data generation\n",
    "\n",
    "    # Update the predictors and target attributes accordingly\n",
    "    # predictors = balanced_data.drop('target_attribute', axis=1)\n",
    "    # target = balanced_data['target_attribute']\n",
    "\n",
    "    # Print the updated target balance\n",
    "    # updated_target_counts = balanced_data['target_attribute'].value_counts()\n",
    "    # updated_target_balance = updated_target_counts / len(balanced_data) * 100\n",
    "    # print(\"Updated Target Balance:\")\n",
    "    # print(updated_target_balance)\n",
    "else:\n",
    "    print(\"Target balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9b09ec",
   "metadata": {},
   "source": [
    "### C. Perform train-test split and standardise the data or vice versa if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343bef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data (if required)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0917b289",
   "metadata": {},
   "source": [
    "### D. Check if the train and test data have similar statistical characteristics when compared with original data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistical measures for the original data\n",
    "original_mean = df.mean()\n",
    "original_std = df.std()\n",
    "original_corr = df.corr()\n",
    "\n",
    "# Calculate statistical measures for the train and test data\n",
    "train_mean = X_train.mean()\n",
    "train_std = X_train.std()\n",
    "train_corr = X_train.corr()\n",
    "\n",
    "test_mean = X_test.mean()\n",
    "test_std = X_test.std()\n",
    "test_corr = X_test.corr()\n",
    "\n",
    "# Compare statistical measures\n",
    "mean_diff_train = np.abs(original_mean - train_mean)\n",
    "mean_diff_test = np.abs(original_mean - test_mean)\n",
    "std_diff_train = np.abs(original_std - train_std)\n",
    "std_diff_test = np.abs(original_std - test_std)\n",
    "corr_diff_train = np.abs(original_corr - train_corr)\n",
    "corr_diff_test = np.abs(original_corr - test_corr)\n",
    "\n",
    "print(\"Comparison of Statistical Measures:\")\n",
    "print(\"------------------------------------\")\n",
    "print(\"Mean Difference - Train Data:\")\n",
    "print(mean_diff_train)\n",
    "print()\n",
    "\n",
    "print(\"Mean Difference - Test Data:\")\n",
    "print(mean_diff_test)\n",
    "print()\n",
    "\n",
    "print(\"Standard Deviation Difference - Train Data:\")\n",
    "print(std_diff_train)\n",
    "print()\n",
    "\n",
    "print(\"Standard Deviation Difference - Test Data:\")\n",
    "print(std_diff_test)\n",
    "print()\n",
    "\n",
    "print(\"Correlation Difference - Train Data:\")\n",
    "print(corr_diff_train)\n",
    "print()\n",
    "\n",
    "print(\"Correlation Difference - Test Data:\")\n",
    "print(corr_diff_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2e7ef1",
   "metadata": {},
   "source": [
    "### 5. Model training, testing and tuning:\n",
    "### A. Use any Supervised Learning technique to train a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227ce883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7eb526",
   "metadata": {},
   "source": [
    "### B. Use cross validation techniques.\n",
    "### Hint: Use all CV techniques that you have learnt in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bab0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Perform k-fold cross-validation with k=5\n",
    "k = 5\n",
    "scores = cross_val_score(model, predictors, target, cv=k)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"k-fold cross-validation\")\n",
    "print(\"Cross-validation Scores:\", scores)\n",
    "print(\"Average Score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e163dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k)\n",
    "scores = cross_val_score(model, predictors, target, cv=skf)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Stratified k-fold cross-validation:\")\n",
    "print(\"Cross-validation Scores:\", scores)\n",
    "print(\"Average Score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc9cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "# Perform repeated k-fold cross-validation with k=5 and n=3\n",
    "k = 5\n",
    "n = 3\n",
    "rkf = RepeatedKFold(n_splits=k, n_repeats=n)\n",
    "scores = cross_val_score(model, predictors, target, cv=rkf)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Repeated k-fold cross-validation:\")\n",
    "print(\"Cross-validation Scores:\", scores)\n",
    "print(\"Average Score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf6126",
   "metadata": {},
   "source": [
    "### C. Apply hyper-parameter tuning techniques to get the best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34695b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the hyperparameter grid to search through\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(predictors, target)\n",
    "\n",
    "# Print the best hyperparameters and accuracy\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df572ac",
   "metadata": {},
   "source": [
    "### D. Use any other technique/method which can enhance the model performance.\n",
    "### Hint: Dimensionality reduction, attribute removal, standardisation/normalisation, target balancing etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d6e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the feature selector\n",
    "selector = SelectKBest(score_func=f_classif, k=10)\n",
    "\n",
    "# Fit the selector to the training data\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training and testing data\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Train the model on the selected features\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2588d9b",
   "metadata": {},
   "source": [
    "### E. Display and explain the classification report in detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a9977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(matrix)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matrix, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7008b8",
   "metadata": {},
   "source": [
    "### F. Apply the above steps for all possible models that you have learnt so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1776f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Generate random classification data for demonstration\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "\n",
    "# Convert the target variable to 0 and 1\n",
    "y = np.where(y == 0, 0, 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {'Model': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-score': []}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results['Model'].append(model_name)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Precision'].append(precision)\n",
    "    results['Recall'].append(recall)\n",
    "    results['F1-score'].append(f1)\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort the DataFrame based on the evaluation metric of your choice\n",
    "sorted_results = results_df.sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "# Select the best model\n",
    "best_model = sorted_results.iloc[0]['Model']\n",
    "\n",
    "# Display the results\n",
    "print(sorted_results)\n",
    "print('\\nBest Model:', best_model)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matrix, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba78a10",
   "metadata": {},
   "source": [
    "### 6. Post Training and Conclusion: \n",
    "### A. Display and compare all the models designed with their train and test accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44223f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2299ff56",
   "metadata": {},
   "source": [
    "### B. Select the final best trained model along with your detailed comments for selecting this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0b89be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Define the models\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {'Model': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-score': []}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results['Model'].append(model_name)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Precision'].append(precision)\n",
    "    results['Recall'].append(recall)\n",
    "    results['F1-score'].append(f1)\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort the DataFrame based on the evaluation metric of your choice\n",
    "sorted_results = results_df.sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "# Select the best model\n",
    "best_model = sorted_results.iloc[0]['Model']\n",
    "\n",
    "# Display the results\n",
    "print(sorted_results)\n",
    "print('\\nBest Model:', best_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adfa157",
   "metadata": {},
   "source": [
    "### C. Pickle the selected model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0937f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming you have selected the best model and stored it in the 'best_model' variable\n",
    "\n",
    "# Pickle the selected model\n",
    "with open('selected_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(\"Model pickled and saved as 'selected_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80837b",
   "metadata": {},
   "source": [
    "### D. Write your conclusion on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f768c639",
   "metadata": {},
   "source": [
    "Based on the analysis performed, we trained and evaluated several models including K-Nearest Neighbors (KNN), Support Vector Classifier (SVC), XGBoost, Logistic Regression, and Decision Tree. Each model was trained and evaluated using various evaluation metrics such as accuracy, precision, recall, and F1-score and was found that XGBoost is best suited for this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851f554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
